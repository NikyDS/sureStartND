# sureStartND
This is a repository for the Suretart deep learning track for Niky aka Nikoly Dos Santos.  
<h3> RESPONSES   </h3>
<h5> Day 107/06/2021  </h5>
I hope to learn more about AI as I am thinking about getting a Ph.D with an machine learning focus. Generally, I think AI is very interesting and a way to help others on varying tasks.   
<h5> Day 2 07/07/2021.  </h5>
I learned about the importance of my story and the necessity of descriptive words in order to get the audience to truly understand and relate to my story.  
<h5> Day 3 07/08/2021.  </h5>
1. In supervised learning, we know what the output is supposed to be.  
2. Scikit-Learn utilizes other libraries to visualize data.  
<h5> Day 4 07/09/2021.  </h5>
I think the United States has a big problem with the incarceration population. People are given different sentences for the same crime. Parole is also given at different rates. I would like to create a recurrent neural network that would take information about different sentences, without accounting race, and give a similar sentence to the ones previously given in the last 5 years. I found this link, and while it does not contain the specific sentence and crime information, it does help show why this is such a big problem: https://www.sentencingproject.org/publications/no-end-in-sight-americas-enduring-reliance-on-life-imprisonment/
<h5> Day 7 07/12/2021.  </h5>
1. Tensors are multidimensional data arrays and software like tensorflow perform operations which neural networks perform on tensors according to the links provided. <br>
2. I think what was most interesting about the computations was the speed they were completed at. The program calculated a lot of different things very quickly and the different libraries helped make the code much more readable. 
<h5> Day 10 07/15/2021 <br> </h5>
1. I think that a really good point about algorithms meeting percentages was brought up. It is hard to get the perfect data because different times bring different data. It is important to find an algorithm that is adaptable and meets those standards. <br>
2. I actually have a really recent example. I was calling samsung customer service to help my dad with with his camera system and the AI kept thinking that I wanted help with my phone camera. It kept sending me to the wrong person for help and overall it took was longer than necessary to solve my problem. As a result of more people needing help with their phones, the AI struggled with identifying problems with the same key words for other devices. 
<h5> Day 11 07/16/2021 <br> </h5>
So CNN involves three layes and "specializes in processing data that has a gridlike topology" which an example is images. The three layers of CNN are the convolutional layer, the pooling layer, and the fully connected layer. The convolution layer is the core building block and holds the main portion of the networks computational hold. It performs dot product mathematics agaisnt two matrices and is made up of sparse interaction, parameter sharing, and equivalent representation. <br>
The next layer is the pooling layer which "replaces the output of the network at certain locations by deriving a summary statistic of the nearby outposts." The final layer, the fully connected layer has "full connectivity with all the neurons in the preceding and succeeding layer." This allows it to be computed as usual by matrix multiplication instead of the dot product. It does need to incorportate the bias effect as welll. <br>
<h5> Day 15 07/20/2021 </h5> <br>
Some of the advantages of ReLU is that it is super easy to implement requiring only a max function, it avoids the vanishing gradient problem, it actually achieves a true zero, and it is a lot less computationally expensive than tanh and sigmoid. One example given in the text is the ImageNet classification. 

